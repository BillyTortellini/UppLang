Some thoughts about the general Compiling-Process:
    - Intermediate-Code Generation and Semantic-Analysis should be 2 different Steps, and the
        Analysis should only 'decorate' some form of the AST. Although this is problematic 
        when parts of the AST need to be analysed multiple times (defer, polymorphic-instances, macros)

        The reason I would like this is that I can have a more stop and continue analysis, 
        instead of requiring all Dependencies of e.g. a function to be complete.
        For example, after knowing all Struct-Members I could already analyse Headers and Code,
        but for Compilation/Member-Access analysis I would stop and wait for the specific Event to occur.

        Also, with the event structure it still allows me to detect loops, If no workload is executable, 
        we just need to trace the events

    - The RC_Analyser should contain more detailed information where Symbol-Reads occur.
        Maybe even on statement/expression level

    - Instead of the Workload-Dependency System (Workloads waiting on other Workloads or on Symbols)
        an Event-Based System would be nicer. 

        Why?
        An Event-Based System is likely more fine grained, as seen with the struct reachability problem.
        Thats a wrong conclusion, because this only depends on the Fact if we can Start/Stop specific workloads
        at any given time.

    - Ok, instead of a stop and go approach



General Problem Statement:
    Because my Langauge should be able to handle #bake's, comptime Code-Execution,
    Conditonal Compilation and other Stuff, the Dependencies between Analysis Items 
    becomes a Graph and not just a Tree that can be solved. This means that
    during the Analysis Process we need to figure out in which order the Items need
    to be analysed. 
    The Dependencies that currently exist in the language are:
        - Symbol_Reads must be resolved before an Analysis of ID Expressions
        - Function-Header must be analysed before Analysis of Function_Calls/Function_Pointer_Reads

    One Solution to this Problem is to have a Pausable Analysis. With this Approach
    Dependency-Detection can happen during the Analysis (E.g. finding an unresolved Symbol-Read)
    and we can switch to other workloads until the Dependency is resolved. 
    The Problem with this Approach is that a Start-Stop Mechanism needs to be implemented,
    which makes the Analysis more complicated, and also slower, since a lot of small Starts/Stops may
    be required
    
    The other Type of solution is to detect all Dependencies of a single Analysis Item
    beforehand, so that the the Analysis of the Items is efficient and simple.
    This has the Requirement that we prescan all Analysis-Items to find Dependencies.
    All Dependencies between Items are either based on
        - Symbol-Reads
        - Internal Definitions (Definitions inside Function Body, Anonymous structs in structs, Bakes)

Shouldn't Type_Info be comptime known?
No, but it should be comptime evaluable
BUFFER_SIZE :: type_info(type_of(x)).size









Design Questions:
    Array-Index checking
    Casting a negative signed value to unsigned should cause a panic?
    Delete should set the pointer to null
    Rune Type instead of char?


DESIGN: Project Structure
--------------------------------
In other Programming languages Projects are structured usually by:
    - Providing Namespace Structures (C++: Namespace, Java: Module, ...)
    - Different Files on the Filesystem
    - Different Folders on the Filesystem
    - An Import/Include System to load other files (Recursively)

Usually the Import System is recursiv, but two different branches will
still need to import the same items (E.g. Specify the same filename) in multiple files

I want a module/namespace System inside the language, and also a file-include system
This is quite similar to other languages, with the difference that one project does not span multiple Folders/Files
but rather contains all functions and stuff inside one single, big file.
Then importing a library is simply loading one project-file.

There will be a keyword to load a project, and during Comptime-Execution or in Conditional-Compilation (#ifs)
projects can be loaded, so that we have support for changing Dependencies on the fly (E.g. Multi-Platform Development)
    #load "../../Basics.upp" as Basics
    #load "../../Datastructures.upp" as Datastructures
Load loads all Symbols of the loaded Project into a given Module.
Multiple load of the same File don't do anything, they only create a new Symbol referencing that Project

How conditional loading of Projects will work internally is dependent on how Conditional Definitions
of Symbols work, which isn't decided yet.


DESIGN: Symbol/Module Imports
--------------------------------
Symbol/Module Imports are done with a specific keyword, called using.
In it's simplest case, using can import one Symbol from another module
    Helpers~foo()
    using Helpers~foo
    foo()

Using is also Order-Independent, and influences the whole scope where it was used
    foo()
    using Helpers~foo

Single item Imports can also be given Aliases
    using Helpers~create_and_update_after_validation as cuv
    cuv()
    
Using may also import all Symbols of a Module at once
    Helpers~foo()
    Helpers~bar()
    using Helpers~*
    foo()
    bar()

Fact: Using always refers to modules, and either imports a single item from a module or all children.
If a single Symbol is imported, it is implemented like this
    using gets its own Workload.
    AST-Analyser adds a new Alias-Symbol (foo) inside the Symbol-Table.
    If a Workload references this Alias-Workload, a dependency to the Alias-Workload is created.
    Once the alias-workload finishes, all symbol reads of the alias are re-evaluated, and the correct dependencies
    are added to the workloads that wait on the alias.
If multiple Symbols are imported 
    The Symbol-Table is tagged as unfinished, and all symbol-reads from inside this Symbol-Table will not
    succeed until the using Workload is resolved. There will be special Symbol-Reads which are still allowed
    to execute, like other usings.

Will importing all Symbols also import all usings?
    No, I strictly do not want that, because I want to keep all namespaces clean
        Helper :: module
            Help :: struct {}
            foo :: () {}
        Player :: module
            bar :: ()
            using Helper~*
        Program :: module
            using Player~*
            main :: ()
                x := bar()
                y := foo() // !ERROR: foo is only imported in Player
                z := Helper~foo()

Since Structs and Enums also act like small Namespaces, the use of using isn't that wrong, although the
using then needs to be applied on a variable, and not on a Type name
    x: Player;
    x.name = "Fred";
    x.age = 15;
    using x;
    name = "Fred";
    age = 15;

This can also work inside the Definitions of Structs/Enums
    Player_Info :: struct
        using member: *Player
        game_time: int
    x: Player_Info = get_info(player)
    x.name = "Fred"
    x.game_time = 15

Can imported Symbols Overload/Shadow other Symbols?
    If not, we don't even need the waiting on the using, since the reads won't resolve until we imported the Symbols

Are usings inside Conditonal Compilation legal?
    I don't think that this is particularely useful Use-Case, but single-import symbols are ok,
    and multi-import symbols are probably problematic, and I probably just want to disallow them,
    because of the following use case:
        #if OS == .WINDOWS
            using Win32~*
        #else 
            using Linux~*
    Is the symbol read of OS allowed to execute?


DESIGN: Symbol Redefinitions:
-----------------------------
There are 3 types of Symbol Redefinitions (Symbols referenced in the same ID in connected scopes)
Overloading:
    2 Symbols in the same Scope (Function overloading)
        add :: (x: int)
        add :: (p: Player)
Shadowing:
    2 Symbols in an ordered environment in the same Scope (Code, actually only valid for variable shadowing)
        x: int = 5
        a = x + 10
        x: bool = false
        if x {}
Overwriting:
    2 Symbols in different connected scopes
        x: int = 15
            a = x + 10
            x: bool = false

I don't see any real Use-Cases for Shadowing, so I don't want to implement it.
I think Overloading has some uses, and I have one specific use case for Overwriting.

Because new Symbols can be define during analysis (Conditional Loading of Projects, Comptime-Execution)
implementing overloading/overwriting is made harder in some cases. This could be solved with a 'Generation'-System,
where Symbols defined in later generations must not shadow/overwrite/overload previous Symbols

When Overwriting is disallowed, defining Symbols/Importing Symbols also
need to check lower Scopes, not just Scopes above them. This can be somewhat efficiently implemented by using
a Hashtable of all defined Symbols, and rechecking the symbols of previous generations

Overloading: If Symbols can be overloaded, we need Semantic Information to check if the overload is valid.
    Checking if an Overload is valid depends on the given Casting-Rules, which will be problematic in
    this language, because Casting will be different depending on the Context.
    Also, if the Symbol is then referenced, we also need Semantic Information to know which 
    of the Symbols to pick.
    
    The only real Use-Case of this is Function Overloading and Template Specialization,
    and it may be possible to implement for polymorphic structs
So I think I will disallow overloading for the time beeing and maybe think about it again
when I need some type of template specialization.
Other Ideas that could achieve the same Goal as Overloading is to have special Syntax for Polymorphic-Specialization,
or to use Explicit Overloading, like in Odin
    add_ints(a: int, b: int) -> int {}
    add_floats(a: float, b: float) -> float {}
    add :: overload{add_ints, add_floats};
    
    x := add(5, 7);
    y := add(7.3, -19.2);

There is one use case that I have for Overwriting: Having something have the same name as a Module.
This is often the case, because Modules are named after what they are doing.
Overwriting would be required in this case, otherwise this would result in an error
    Hashtable :: module
        Hashtable :: struct 

But even with Overwriting, the usage of this would be:
    x: Hashtable~Hasthable(int)
Because
    using Hashtable~Hashtable 
would bring Hashtable into the same scope as Hashtable, requiring overloading.

To solve this Problem, I think I want to be able to have a 'Drill-Down' Behavior on pure Module reads (No ~)
    x: Hashtable(int);
With the exception being Contexts where a module is required, like Identifier Paths
    Hashtable~create
Or
    using Hashtable~create
This generates a difference between
    using Hashtable as Alias1   // Alias1 is a Module
    Alias2 :: Hashtable         // Alias2 is a Datastructure/function/the drilled down thing



DESIGN: Operator Overloading/DotCalls:
--------------------------------------
Both Operator Overloading and DotCalls allow similar functionality:
Add some information to a Type, which makes specific Syntax execute functions.

In this language I do not want to implicitly have Operator Overloading/DotCalls, but I would
rather have the User enable these things if necessary. 
    Operations :: #Operators(Dynamic_Array) {
        []: dynamic_array_get;
        +: dynamic_array_append;
        .add: dynamic_array_add;
        .remove: dynamic_array_remove_element // Shorthand for the previous line
    }
    
    x: Dynamic_Array;
    a := dynamic_array_get(x, 5);
    a := dynamic_array_append(x, y);
    dynamic_array_remove_element(x, 5);
    using Operations;
    a := x[5];
    a := x + y;
    x.remove(5);

Maybe I also want all Operations related to type, which also includes Implicit and Explicit casting
to not be available by default. This would cause the normal namespace to be completely empty,
and all Operations need to be first imported.

DESIGN: Conditional Compilation:
--------------------------------
#if foo()
    using Math~Quaternion
#else
    using Nintondo~Quaternion
    #if bar()
        Quaternion :: struct 
            x,y,z,w: float;

I mean I can obviously detect which symbol definitions are dependent on #IFs,
and if a symbol like this is referenced, I can add a dependency on the #if Workload. 
This also seems to be the way this should be handled
Now the question is, are paths that conditionally reference things analysed? I think so.

OS :: enum {WINDOWS; LINUX; MAC}.WINDOWS;
main :: ()
    #if OS == .WINDOWS
        win32_call()
    #else if OS == .MAC
        mac_call()
    #else
        linux_call()

In these situations a start and stop system is definitly simpler than a Up-Front Dependency system
To be fair I don't plan on implementing Conditional-Compilation or Overloading in the near future, 
but it is something to keep in mind.

The Point is that Conditional-Compilation is one of the Features that may require some Form of Stop-And-Go
analysis, because we sometimes may need to wait on usings before we can do anything else inside this Scope.

#if foo()
    using Vector_Math~*
#else
    using Normal_Math~*
Everything inside this Scope now has a dependency on the using



What are the currently unsolved/hard Problems of parsing this language?
    - Defer/Macros/Polymorphic-Instanciation requires multiple parses of the same AST-Nodes
        This is problemantic because this way I cannot attach Analysis-Information directly on the AST-Nodes,
        because this Information would be overwritten by following passes
    - Defer interaction with Blocks, returns, breaks/continues
    - Named Breaks/Continues act like switches and require correct defer handling + something like gotos
    - Inner Definitions of Constant-Values/Functions/Structs
    - Anonymous struct/enum definitions
    - Auto casting requires context in binary expressions is hard
    - Bake/Runtime Code execution creates a Dependency-Graph that may contain Loops
    - Runtime Code execution can interact with the compilation process
    - When is Runtime-Code executed when working in an IDE
    - Symbols can be defined after runtime, and Overwriting/Shadowing/Overloading is disabled
    - Static #If is problematic with the current structure, because the dependencies of the Analysis_Item depend on the value
        of the static if.
    - Polymorphic-Parameter resolution seems to require multiple parses of the parameters, making it hard to do 
        when generating code while analysing
    - Expressions in this language have a context, meaning that analysis passes information down the Expression-Tree
    - More Complicated Casting due to how pointers are handled
    - How do I prevent Errors from creating other Errors, flooding the Message-Logs
        Connected: What to do in template analysis when we access Members of a polymorphic type?
                   What to do with bakes inside of a Polymorphic Function
    - How would I implement constant parameters
        This is necessary to have a proper distinction between in, in-out and out parameters
    - Control-Flow Analysis for missing returns is required in this language, and should be done during analysis
    - Some Analysis-Parts require generation of new Variables, like a valued return with defers, or
        a switch case with auto pointer variables
    - Attribute Tags will be necessary at some point
    - Functions and Structs can refer to themselves with their name
    - Functions can only be compiled if all referenced functions are also compiled, 
        creating a web of function compilation where cycles are allowed
    - Compile time Code executing Order dependency is unknown, do we need Synchronization?
        What to do with Global Variables during Code-Execution
    - Array-Size inside Struct-Compilation
    - Operator Overloading
    - Using for implicitly importing Struct members



    

AST-Processor Output:
 - Definitions (Globals + Comptime Definitions like Types, Functions, Constants)
 - Project-Loads
 - Extern Things
 - #if (Which needs evaluation before other AST-Processor Items can be generated)
 - #run (Where we can set build options, which function is main, target platform and stuff)

What does the analyser do after the AST-Processor finished?
 1. Load all Projects recursively (Imported Projects can load other Projects) which aren't inside #if's or #run's
 2. Create all Definition Symbols (So that as much symbols as possible are defined at once)
 3. Create workloads for definitions (Global or Comptime analysis), create dependencies between Symbols and Workloads
 4. Create workloads for #ifs
 5. Execute all workloads, If new AST-Items are added, analyse them after all Workload-Progress comes to a halt

Where are Symbol-Reads and Dependencies stored?
    I feel like every expression in the language should have a base expression that contains an array of all symbol reads.
    E.g. every time an expression is started (The parent of the expression is not an expression), a base expression is added

Where can Base-Expressions occur?
 - Comptime-Definition
 - Global Definition
 - Functions (Parameter Types + Return type)
 - Structs
 - Enums
    









#if fib(5) == 38
    foo :: (a: int) -> int 
        return a * 2
#else
    foo :: (x: bool, z: int) -> bool 
        return x && z % 2 == 0
#end



Everything where Comptime is needed:
    - Polymorphic Arguments
    - Switch Cases
    - Comptime Definitions
    - Array Size
    - Rune-Type for Strings

Old Approach:
    - Run over the AST and create workloads as we go.
    - Dependencies were managed by creating dependencies on other workloads on the fly
    - There was a start/stop system that could stop between statements, but not for expressions.
        -> Expressions had to be deleted on Dependencies (Or Cached in cases like Bake/Lambdas)
    - Circular Dependencies just reported an error, but there was no possibility to Resolve them (No Symbol-Reads to set to error...)
    - Lots of starting/stopping and waiting for dependencies
    - Order-Independent Comptime-Declarations were bound by dependencies, and Inner-Definitions could not be resolved

New Approach:
    - Scan for Analysis-Items and all Dependencies beforehand
    - Only if all Dependencies of one Workload are done, the workload can be executed
    - All dependencies of a workload need to be created before the workload is created
    - Struct-Reachable problem, requiring Clustering System and new workloads

Next Approach:



        
 TODO:
    Lexer:       Needs to parse $
    Parser:      Function parameters can start with $
    IR-Code:     Needs to store the parameter symbols in a new table, each parameter Symbol-Read can read from this table
                    also needs to save if it is a polymorphic parameter
    Analyser:
                 Needs to evaluate the arguments in the correct order, do this by
                    checking the symbol reads of the analysis-item (not workload, since workload only contains dependencies)

Type-Constructors:
    ID                ... Type-Reference
    *Type             ... Pointer
    []Type            ... Slice 
    [2]Type           ... Array
    (x: Type) -> Type ... Function
    struct {a: Type}  ... Struct

    

x: Dynamic_Array(int);
a: x.Value_Type; // Should be a comptime Type

Polymorphic Functions, Simple to Complex:
-------------------------------------
$ before an argument makes it comptime, and the function is 'polymorphic'
    foo :: ($count: int) {
        arr: [count]float; // Works because it is comptime known
        x :: count + 32;
        arr_2: [x]float;
    }

Types can be polymorphic, and variables can then be instanciated
    foo :: ($A: Type) 
    {
        x: A;
        xp: *A;
        xp = *x;
    }

Other parameters can access Polymorphic arguments by name
    foo :: ($A: Type, x: A, y: A)
    {
        z: A = x + y;
    }

    foo :: ($A: Type, $count: int, arr: [count]A)
    {
    }

Order of accessing the arguments does not matter
    foo :: (x: [count]A, $A: Type, $count: int)
    {
    }

The Return Type can also access Polymorphic arguments
    foo :: ($A: Type, $count: int) -> [count]A
    {
        a: A;
        return a;
    }
    x: int;
    foo (int, x, 5);

Because having a comptime type and using it as an argument will be a common pattern
there will be a shorthand for it, which does the exact same thing
    foo :: ($A: Type, x: A) {}
    foo :: (x: $A)          {}
    foo :: (x: $A, y: A)    {}
    foo :: (x: struct{a: $A; b: $B;}) {} // This is somewhat problematic, because I cannot tell how I would call this.

    z: struct{a: int, b: bool} = .{5, false};
    foo(z);
    foo(.{15, false});

    // Errors:
    foo :: (x: $A, y: $A)   {} // 2 Arguments with name A, both of type Type
    foo :: (x: [$count]$A)  {} // Count is now of type Type, not int, so it cannot be used in array

Since the return type did not have a name, we could not make it polymorphic before, 
but now this is possible. Return Types must either be specified by name or evaluated by Expression-Context
    foo :: () -> $A {
        x: A = 5;
        return x + 5;
    }
    x0 := foo(A = int); // Works
    x1: int = foo();    // Works with Expression-Context
    x2 := foo();        // Error, cannot determine polymorphic argument A



For API Design:
    table_create :: () -> $Table_Type/Hashtable {
        return new Table_Type;
    }
    table_create :: () -> result: Hashtable {
        return new type_of(result);
    }
    table_add :: (table: *$T/Hashtable, key: table.Key_Type, value: T.Value_Type)
    {
        table = new T;
        table.entries = ...;
        table.size = ...;
    }
    table_add :: (table: *Hashtable, key: table.Key_Type, value: T.Value_Type)
    {
        table = new type_info(type_of(table)).options.pointer_child;
        table.entries = ...;
        table.size = ...;
    }


    test :: (a: $T, x: #bake(Type) {return get_smallest_member_type(T);})





// How I would like to use #if in structs
Dynamic_Array :: module
    Dynamic_Array :: struct(Element_Type: Type, use_allocator: bool = false)
        buffer: [Type]
        size: int;
        #if use_allocator
            allocator: *Allocator;

    create :: (initial_capacity := 1) -> $T/Dynamic_Array
        result: T;
        result.buffer = new [initial_capacity]T.Element_Type;
        result.size = 0;
        #if T.use_allocator
            result.allocator = Compiler~context.allocator;
        return result;


using Datastructures~Dynamic_Array;
using Dynamic_Array::Operators;

x: Dynamic_Array(int);
x := Dynamic_Array~create();   // Type can be infered by context
defer x.destroy();
y: Dynamic_Array(float, true);
y := Dynamic_Array~create();
x.add(5);
defer y.destroy();

x := create();
destroy(x);





Memory :: module
    copy :: (destination: []byte, source: []byte)
        assert(destination.size == source.size);
        loop i in Range(0, destination.size)
            destination[i] = source[i];
        
Dynamic_Array :: module
    Dynamic_Array :: struct(Element_Type: Type)
        buffer: []Type
        size: int 

    Operators :: #Operators(Dynamic_Array)
        Dotcall: destroy
        Dotcall: reserve
        Dotcall: add
        [int]: get;
        +: (array: *Dynamic_Array($T), other: *Dynamic_Array(T)) -> Dynamic_Array(T)
            result := Dynamic_Array~create(Element_Type = T)
            add(result, array)
            add(result, other)
            return result
    using Operators

    create :: (capacity := 1) -> $T/Dynamic_Array
        return .(buffer = new [capacity]T.Element_Type, size = 0)

    destroy :: (using array: *Dynamic_Array)
        delete buffer;
        size = 0;

    reserve :: (using array: *Dynamic_Array, new_capacity: int)
        if new_capacity <= buffer.size then return;
        new_buffer := new array.Element_Type[new_capacity];
        Memory~copy(new_buffer.data, buffer.data, sizeof(array.Element_Type) * new_capacity);
        delete buffer;
        buffer = new_buffer;

    get :: (array: Dynamic_Array, index: int) -> *array.Element_Type
        if index < 0 || index > array.size panic();
        return array.buffer[index];

    add :: (using array: *Dynamic_Array, value: array.Element_Type)
        if size + 1 >= buffer.size
            reserve(array, buffer.size * 2)
        buffer[size] = value
        size += 1

    add :: (using array: *Dynamic_Array, values: []array.Element_Type)
        using Memory~to_bytes;
        using Memory~copy;
        while size + values.size >= buffer.size
            array.reserve(buffer.size * 2)
        buffer_start := type_of(buffer).(*buffer[size], values.size);
        copy(to_bytes(buffer_start), to_bytes(values));
        size += values.size;


using Datastructures~Dynamic_Array
using Dynamic_Array~Operators

x := Dynamic_Array~create(Element_Type = int)
defer x.destroy()
y := Dynamic_Array~create(Element_Type = int)
defer y.destroy()

x.add(5)
x[0] = 17
a := x[0] * 2
x.add(.[1, 2, 3, 4, 5])
loop i in x
    print("%d ", i)
print("\n")









Named Arguments:
    one   :: (a: int)         {}
    two   :: (a: int, b: int) {}
    three :: (a: int, b: int, c: int) {}

Arguments don't need to be named, if they are given in order
    one(1)
    two(1, 2); 
    three(1, 2, 3);

But they can be named
    one(a = 1);
    two(a = 1, b = 2);
    three(a = 1, b = 2, c = 3);

    one(z = 5);        // Error: No argument called z
    two(a = 1, a = 2); // Error: Argument already supplied, missing argument b

What if only parts of the arguments are named?
    two(1, b = 2);








-----------------
--- USE_CASES ---
-----------------

Dynamic_Array :: module
{
    Dynamic_Array :: struct(Element_Type: Type)
    {
        buffer: []Element_Type;
        size: int;
    }

    create :: (capacity: int = 1) -> $T/Dynamic_Array {
        return .{buffer = new [capacity]T.Element_Type; size = 0;};
    }

    destroy :: (array: *Dynamic_Array)
    {
        delete buffer; // Should delete set the pointer to 0?
        size = -1;
    }

    reserve :: (array: Dynamic_Array, capacity: int)
    {
        if (array.buffer.size >= capacity) return;
        new_buffer := new array.Element_Type[capacity];
        Basics~Memory~copy(array.buffer.data, new_buffer.data, sizeof(array.Element_Type) * array.buffer.size);
        delete array.buffer;
        array.buffer = new_buffer;
    }

    add :: (array: Dynamic_Array, value: array.Element_Type) 
    {
        if array.size + 1 > array.buffer.size {
            reserve(array, array.buffer.size * 2);
        }
        array.buffer[array.size] = value;
        array.size += 1;
    }
}

a: Dynamic_Array(float);
a = Dynamic_Array~create(capacity = 5);
defer Dynamic_Array~destroy(a);

b := Dynamic_Array~create(Element_Type = int);
x: a.Element_Type;

module Hashtable
{
    Entry: struct(Key_Type: Type, Value_Type: Type)
    {
        key: Key_Type;
        value: Value_Type;
        valid: bool;
        hash: u64;
        next: *Entry(Key_Type, Value_Type);
    }

    Hashtable :: struct(Key_Type: Type, Value_Type: Type, hash_fn: (a: Key_Type) -> u64, equals_fn: (a: Key_Type, b: Key_Type) -> bool)
    {
        entries: []Entry(Key_Type, Value_Type);
        count: int;
    }

    create :: () -> Hashtable
    {
        Table_Type :: Compiler~Return_Type;
        result: Table_Type;
        result.count = 0;
        result.entries = new []Entry(Table_Type.Key_Type, Table_Type.Value_Type);
        for entry : result.entries {
            entry.valid = false;
            entry.hash = 0;
        }
        return result;
    }

    destroy :: (table: *Hashtable) {
        delete table.entries;
    }

    reserve :: (table: *Hashtable, capacity: int)
    {
        ...
    }

    insert :: (table: *Hashtable, key: table.Key_Type, value: table.Value_Type) -> bool
    {
        hash := table.hash_fn(key);
        entry_index := hash % table.entries.size;
    }

    contains :: (table: *Hashtable, key: table.Key_Type) -> bool
    {
        ...
    }
}

using Datastructures~Hashtable; // Imports symbol Hashtable as Datastructures~Hashtable
a: Hashtable(int, String, i32_hash, i32_equals);
a := Hashtable~create(); // This should work based on the return type (E.g. all comptime parameters can be infered)
defer Hashtable~delete(a);
Hashtable~insert(a, 5, "Hello my darling");
Hashtable~insert(a, 3, "Frank");

b: [4]bytes;
loop i in Range(0, b.size)
    print("%", .[it]);
    i + 1;

loop i // while loop
loop i := 0; i< 10; i++
    
switch address
  case .ipv4(bytes):
    loop b in bytes
      print("%", .[b]);
      if iterator::has_next(b) 
        print(".")
  case .ipv5(using v5):
      print("Address: \"%\", Town: \"%\", Code: %", .[address, town, code])
  case .ipv6(v6):
      print(v6);
      a := 5 + if addition then -b else b



Hashtable :: module

    Hashtable :: struct
        entries: []Entries
        count: int

    find_element :: (table: Hashtable, key: table.Key_Type)

    Operators :: module
        operator [](Hashtable): find_element 
        operator .add: add
        operator .destroy: destroy 

using Datastructures~Hashtable
using Hashtable~Operators~*
x: Hashtable(String, int)
defer x.destroy
x.add("Frank", 5)
y := x["Frank"]




Empty Project Example:
FILE_START:
-----------

main :: ()
    i: ~Primitive_Types~i32;
    j := 5;       // Is Unnamed integer type, which when inspected defaults to i32
    i = 2;
    k := ~Operations~i32_add(i, j);


    f: ~Primitive_Types~f32;
    f = ~Casting~i32_to_f32(i); // This is not a function call, but a builtin call


    f: float = i; // Would require an implicit casting from int -> float
    f: float = cast i; // Searches through explicit castings to find float to int
    f: float = 
    

enable auto_dereference;
enable auto_address_of;
